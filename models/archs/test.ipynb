{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "import Norms as Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# 影像轉token序列 (B, C, H, W) to (B, HW, C)\n",
    "def to_3d(x):\n",
    "    \"\"\"Reshape from (B, C, H, W) to (B, HW, C)\"\"\"\n",
    "    return rearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "##########################################################################\n",
    "# token序列轉影像 (B, HW, C) to (B, C, H, W)\n",
    "def to_4d(x, h, w):\n",
    "    \"\"\"Reshape from (B, HW, C) to (B, C, H, W)\"\"\"\n",
    "    return rearrange(x, 'b (h w) c -> b c h w', h=h, w=w)\n",
    "\n",
    "##########################################################################\n",
    "# MLP (flaoat16)\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, dropout=0.1, bias=True):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(dim, 4*dim, bias=bias, dtype=torch.float16)\n",
    "        self.c_proj  = nn.Linear(4*dim, dim, bias=bias, dtype=torch.float16)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float16)\n",
    "        with torch.amp.autocast('cuda'):  # ✅ AMP 自動管理精度\n",
    "            x = self.c_fc(x)\n",
    "            x = F.gelu(x)\n",
    "            x = self.c_proj(x)\n",
    "            x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Token statistics transformer: linear-time attention via variational rate reduction\"\"\"\n",
    "##########################################################################\n",
    "# ToST（Token Statistics Transformer） 版本的自注意力，取代傳統的 QK 相似性計算\n",
    "class CausalSelfAttention_TSSA(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads = 8, block_size = 1024, dropout = 0.1, bias=False , dtype=torch.float16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # query, key, value projections\n",
    "        self.c_attn = nn.Linear(dim, dim, bias=bias, dtype=dtype)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(dim, dim, bias=bias, dtype=dtype)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "        self.n_head = num_heads\n",
    "        self.dim = dim\n",
    "        self.dropout = dropout\n",
    "        self.block_size = block_size\n",
    "        self.temp = nn.Parameter(torch.ones((self.n_head, 1), dtype = dtype))\n",
    "        self.denom_bias = nn.Parameter(torch.zeros((self.n_head, block_size, 1), dtype = dtype))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, N, C) - token 序列\n",
    "        return: (B, N, C) - 經過 TSSA 處理的 token 序列\n",
    "        \"\"\"\n",
    "        x = x.to(torch.float16) # 確保計算在 float16 上執行\n",
    "        B, N, C = x.shape # batch size, sequence length, embedding dimensionality (dim)\n",
    "\n",
    "        with torch.amp.autocast('cuda'):  # ✅ AMP 自動管理精度\n",
    "            # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "            w = self.c_attn(x).view(B, N, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "            w_sq = w ** 2\n",
    "            denom = (torch.cumsum(w_sq,dim=-2)).clamp_min(torch.finfo(torch.float16).eps) # cumulative sum\n",
    "            w_normed = (w_sq / denom) + self.denom_bias[:,:N,:]\n",
    "        \n",
    "            # calculate attention weights\n",
    "            tmp = torch.sum(w_normed, dim=-1)* self.temp\n",
    "            Pi = F.softmax(tmp, dim=1) # B, nh, T\n",
    "        \n",
    "            # calculate attention\n",
    "            dots = torch.cumsum(w_sq * Pi.unsqueeze(-1), dim=-2) / (Pi.cumsum(dim=-1) + torch.finfo(torch.float16).eps).unsqueeze(-1)\n",
    "            attn = 1. / (1 + dots)\n",
    "            attn = self.attn_dropout(attn)\n",
    "        \n",
    "            # apply attention weights and combine heads\n",
    "            y = - torch.mul(w.mul(Pi.unsqueeze(-1)), attn)\n",
    "            y = y.transpose(1, 2).contiguous().view(B, N, C) # re-assemble all head outputs side by side\n",
    "            y = self.resid_dropout(self.c_proj(y))\n",
    "            \n",
    "        return y\n",
    "\n",
    "##########################################################################\n",
    "# ToST（Token Statistics Transformer）塊\n",
    "class ToSTBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim = 1024, norm_type='WithBias'):\n",
    "        super().__init__()\n",
    "        self.ln_1 = Norms.Norm(dim, norm_type) # LayerNorm\n",
    "        self.attn = CausalSelfAttention_TSSA(dim) # TSSA\n",
    "        \n",
    "        self.ln_2 = Norms.Norm(dim, norm_type) # LayerNorm\n",
    "        self.mlp = MLP(dim)\n",
    "        eta = torch.finfo(torch.float16).eps\n",
    "        self.gamma1 = nn.Parameter(eta * torch.ones(dim), requires_grad=True)\n",
    "        self.gamma2 = nn.Parameter(eta * torch.ones(dim), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, C, H, W) - 影像特徵圖\n",
    "        return: (B, C, H, W) - 經過 ToST 處理的影像特徵圖\n",
    "        \"\"\"\n",
    "        _, _, H, W = x.shape\n",
    "        \n",
    "        x = x + self.gamma1.view(1, -1, 1, 1) *to_4d(self.attn(self.ln_1(to_3d(x))), H, W)\n",
    "        x = x + self.gamma2.view(1, -1, 1, 1) *to_4d(self.mlp(self.ln_2(to_3d(x))), H, W)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azurl\\AppData\\Local\\Temp\\ipykernel_1292\\130657001.py:19: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=True)  # ✅ 允許 AMP\n",
      "C:\\Users\\azurl\\AppData\\Local\\Temp\\ipykernel_1292\\130657001.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n",
      "C:\\Users\\azurl\\AppData\\Local\\Temp\\ipykernel_1292\\3245774369.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.amp.autocast('cuda'):  # ✅ AMP 自動管理精度\n",
      "C:\\Users\\azurl\\AppData\\Local\\Temp\\ipykernel_1292\\1297796864.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.amp.autocast('cuda'):  # ✅ AMP 自動管理精度\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入形狀： torch.Size([2, 1024, 32, 32])\n",
      "to3d torch.Size([2, 1024, 1024])\n",
      "NORM torch.Size([2, 1024, 1024])\n",
      "CausalSelfAttention_TSSA torch.Size([2, 1024, 1024])\n",
      "to4d torch.Size([2, 1024, 32, 32])\n",
      "to3d torch.Size([2, 1024, 1024])\n",
      "MLP torch.Size([2, 1024, 1024])\n",
      "to4d torch.Size([2, 1024, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azurl\\AppData\\Local\\Temp\\ipykernel_1292\\130657001.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):  # ✅ AMP 運行\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ToSTBlock 測試通過，一切正常！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# 設定測試參數\n",
    "B = 2       # batch size\n",
    "C = 1024    # 通道數 (與 dim 對應)\n",
    "H = 32      # 高度\n",
    "W = 32      # 寬度\n",
    "dtype = torch.float16  # 減少內存佔用\n",
    "\n",
    "# 建立 ToSTBlock\n",
    "tost_block = ToSTBlock(dim=C)  # ✅ 放到 GPU，確保 float16\n",
    "\n",
    "# 創建隨機輸入影像特徵 (B, C, H, W)\n",
    "x = torch.randn(B, C, H, W, dtype=dtype)  # ✅ 確保輸入數據是 float16\n",
    "\n",
    "# 設定 AMP（混合精度）\n",
    "scaler = GradScaler(enabled=True)  # ✅ 允許 AMP\n",
    "\n",
    "# 使用 AMP 進行前向運算\n",
    "with autocast(dtype=torch.float16):\n",
    "    y = tost_block(x)\n",
    "\n",
    "# 測試 1: 檢查輸出形狀是否正確\n",
    "assert y.shape == x.shape, f\"ToSTBlock 輸出形狀錯誤！預期 {x.shape}，但得到 {y.shape}\"\n",
    "\n",
    "# 測試 2: 檢查是否有 NaN 或 Inf\n",
    "assert not torch.isnan(y).any(), \"ToSTBlock 輸出包含 NaN！\"\n",
    "assert not torch.isinf(y).any(), \"ToSTBlock 輸出包含 Inf！\"\n",
    "\n",
    "# 測試 3: 反向傳播測試\n",
    "optimizer = torch.optim.Adam(tost_block.parameters(), lr=1e-3)  # ✅ 建立優化器\n",
    "optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "with autocast(dtype=torch.float16):  # ✅ AMP 運行\n",
    "    loss = y.mean()  # 假設損失函數是均值\n",
    "scaler.scale(loss).backward()  # ✅ 使用 AMP 反向傳播\n",
    "scaler.step(optimizer)  # ✅ AMP 更新權重\n",
    "scaler.update()  # ✅ AMP 調整 scale\n",
    "\n",
    "print(\"✅ ToSTBlock 測試通過，一切正常！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
