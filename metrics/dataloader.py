

import os
import torch
from torch.utils.data import Dataset
from torchvision import transforms
from PIL import Image
from pathlib import Path


# è‡ªå‹•æ‰¾åˆ° `GFCS_X` ç›®éŒ„
GFCS_X_ROOT = Path(__file__).resolve().parent.parent  # `metrics` çš„ä¸Šç´šç›®éŒ„
DATASET_ROOT = GFCS_X_ROOT / "data"  # `GFCS_X/data/`

# è¨ˆç®— mean/std çš„ç¨ç«‹å‡½æ•¸
def compute_mean_std(mode='train', dataset_name='Rain13K', device='cpu'):
    """
    è¨ˆç®—æŒ‡å®šè³‡æ–™å¤¾å…§æ‰€æœ‰åœ–ç‰‡çš„ mean å’Œ std
    """
    input_dir = DATASET_ROOT / mode / dataset_name / 'input'  # è‡ªå‹•ç²å– input åœ–åƒè·¯å¾‘
    target_dir = DATASET_ROOT / mode / dataset_name / 'target'  # è‡ªå‹•ç²å– target åœ–åƒè·¯å¾‘

    if not input_dir.exists() or not target_dir.exists():
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ•¸æ“šé›†ç›®éŒ„: {input_dir}")
    
    temp_transform = transforms.ToTensor()  # å¼·åˆ¶è½‰æ›ç‚º Tensor
    
    device = torch.device(device) # è¨­ç½®è¨­å‚™

    input_mean = torch.zeros(3, device=device)
    input_std = torch.zeros(3, device=device)
    target_mean = torch.zeros(3, device=device)
    target_std = torch.zeros(3, device=device)
    n_samples = 0

    print(f"ğŸ“Š æ­£åœ¨è¨ˆç®— {mode}/{dataset_name} æ•¸æ“šé›†çš„ mean å’Œ std...")

    input_files = sorted([f for f in os.listdir(input_dir) if f.endswith(('.png', '.jpg'))])
    target_files = sorted([f for f in os.listdir(target_dir) if f.endswith(('.png', '.jpg'))])
    if len(input_files) == 0 or len(target_files) == 0:
        raise ValueError("âŒ æ²’æœ‰æ‰¾åˆ°åœ–åƒæ–‡ä»¶ï¼Œè«‹æª¢æŸ¥æ•¸æ“šé›†è·¯å¾‘ï¼")
    
    for input_file, target_file in zip(input_files, target_files):
        input_img = Image.open(input_dir / input_file).convert("RGB")
        target_img = Image.open(target_dir / target_file).convert("RGB")

        input_img = temp_transform(input_img).to(device)   # è½‰æ›ç‚º Tensor
        target_img = temp_transform(target_img).to(device) 

        input_mean += input_img.mean(dim=(1, 2))
        input_std += input_img.std(dim=(1, 2))

        target_mean += target_img.mean(dim=(1, 2))
        target_std += target_img.std(dim=(1, 2))

        n_samples += 1

    input_mean /= n_samples
    input_std /= n_samples
    target_mean /= n_samples
    target_std /= n_samples
    
    
    print(f"âœ… è¨ˆç®—å®Œæˆï¼š")
    print(f"ğŸ“Š è¨“ç·´æ•¸æ“šé›†çš„ input mean: {input_mean.tolist()}, std: {input_std.tolist()}")
    print(f"ğŸ“Š è¨“ç·´æ•¸æ“šé›†çš„ target mean: {target_mean.tolist()}, std: {target_std.tolist()}")

    return input_mean, input_std, target_mean, target_std


class RainDataset(Dataset):
    def __init__(self, mode='train', dataset_name='Rain13K', 
                 transform=None, test=False, return_size=False):
        """
        mode: 'train' æˆ– 'test'
        dataset_name: æ•¸æ“šé›†åç¨±ï¼Œå¦‚ 'Rain13K' æˆ– 'Rain100L'
        transform: åœ–ç‰‡å¢å¼· / æ¨™æº–åŒ–
        test: æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼ï¼ˆå…è¨± target ç‚º Noneï¼‰
        """
        assert mode in ['train', 'test'], "mode åƒæ•¸å¿…é ˆæ˜¯ 'train' æˆ– 'test'"
        self.input_dir = DATASET_ROOT / mode / dataset_name / 'input'
        self.target_dir = DATASET_ROOT / mode / dataset_name / 'target' if not test else None
        self.transform = transform
        self.test = test
        self.return_size = return_size  # æ˜¯å¦è¿”å›åŸå§‹å°ºå¯¸

        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        if not self.input_dir.exists():
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°ç›®éŒ„ {self.input_dir}ï¼Œè«‹æª¢æŸ¥æ•¸æ“šé›†ï¼")

        if not test and not self.target_dir.exists():
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°ç›®éŒ„ {self.target_dir}ï¼Œè«‹æª¢æŸ¥æ•¸æ“šé›†ï¼")

        # è®€å–åœ–åƒ
        self.input_files = sorted([f for f in os.listdir(self.input_dir) if f.endswith(('.png', '.jpg'))])

        if not test:
            self.target_files = sorted([f for f in os.listdir(self.target_dir) if f.endswith(('.png', '.jpg'))])
            assert len(self.input_files) == len(self.target_files), "âŒ input å’Œ target æ•¸é‡ä¸åŒ¹é…ï¼"

    def __len__(self):
        return len(self.input_files)

    def __getitem__(self, idx):
        input_path = self.input_dir / self.input_files[idx]
        input_img = Image.open(input_path).convert("RGB")
        orig_size = input_img.size  # ä¿å­˜åŸå§‹å°ºå¯¸ (W, H)

        if not self.test:
            target_path = self.target_dir / self.target_files[idx]
            target_img = Image.open(target_path).convert("RGB")
        else:
            target_img = None

        # è½‰æ›åœ–åƒ
        if self.transform:
            input_img = self.transform(input_img)
            target_img = self.transform(target_img) if target_img else None

        return (input_img, target_img) if target_img is not None else input_img


def get_transform(train=True): #mean, std, 
    input_mean = [0.5110453963279724, 0.5104997158050537, 0.4877311885356903]
    input_std = [0.23112213611602783, 0.23167330026626587, 0.23953330516815186]

    target_mean = [0.43193507194519043, 0.43070125579833984, 0.4052175283432007]
    target_std = [0.24484442174434662, 0.2445715367794037, 0.25179967284202576]
    
    if train:
        return transforms.Compose([
            transforms.RandomHorizontalFlip(),  # éš¨æ©Ÿæ°´å¹³ç¿»è½‰
            transforms.RandomRotation(10),  # éš¨æ©Ÿæ—‹è½‰ Â±10 åº¦
            transforms.RandomResizedCrop(256, scale=(0.8, 1.0)),  # éš¨æ©Ÿè£å‰ª
            transforms.ToTensor(),  # è½‰æ›ç‚º Tensor
            transforms.Normalize(mean=input_mean, std=input_std),  # æ¨™æº–åŒ–
            #transforms.Normalize(mean=mean.tolist(), std=std.tolist())  # æ¨™æº–åŒ–
        ])
    else:
        return transforms.Compose([
            #transforms.Resize((256, 256)),  # æ¸¬è©¦æ™‚ç›´æ¥ç¸®æ”¾åˆ° 256x256
            transforms.ToTensor(),
            transforms.Normalize(mean=input_mean, std=input_std),  # æ¨™æº–åŒ–
            #transforms.Normalize(mean=mean.tolist(), std=std.tolist())  # æ¨™æº–åŒ–
        ])
