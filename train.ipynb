{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360e1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from metrics.dataloader import RainDataset, get_transform, compute_mean_std\n",
    "\n",
    "# Import modules\n",
    "from models.archs.DPENet_v1 import DPENet\n",
    "from models.archs.DPENet_v3 import DPENet_v3\n",
    "from models.archs.losses import SSIMLoss_v2, EdgeLoss_v2, L1Loss\n",
    "from models.CosineAnnealingRestartCyclicLR import CosineAnnealingRestartCyclicLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7593ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    \n",
    "    # Ensure specific types\n",
    "    config[\"epochs\"] = int(config[\"epochs\"])\n",
    "    config[\"batch_size\"] = int(config[\"batch_size\"])\n",
    "    config[\"lr\"] = float(config[\"lr\"])\n",
    "    config[\"eta_min\"] = float(config[\"eta_min\"])\n",
    "    config[\"periods\"] = [int(period) for period in config[\"periods\"]]\n",
    "    config[\"restart_weights\"] = [float(weight) for weight in config[\"restart_weights\"]]\n",
    "    config[\"num_workers\"] = int(config[\"num_workers\"])\n",
    "    config[\"log_interval\"] = int(config[\"log_interval\"])\n",
    "    config[\"use_amp\"] = bool(config[\"use_amp\"])\n",
    "    config[\"grad_clip\"] = float(config[\"grad_clip\"])  # 新增梯度裁剪閾值，預設為 1.0\n",
    "    \n",
    "    return config\n",
    "\n",
    "def denormalize(tensor, mean, std, device='cpu'):\n",
    "    \"\"\"\n",
    "    反歸一化 Tensor 將 Normalize(mean, std) 轉回原始範圍\n",
    "    \"\"\"\n",
    "    mean = torch.tensor(mean).view(1, -1, 1, 1).to(device)  # 調整 shape 以匹配輸入\n",
    "    std = torch.tensor(std).view(1, -1, 1, 1).to(device)\n",
    "    return tensor * std + mean  # 反歸一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f09b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始訓練 DPENet_CFIM，使用設備：cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/200]:   0%|          | 0/857 [00:00<?, ?it/s]/home/shuhao/GFCS_X/models/archs/modules.py:670: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epoch [1/200]:  54%|█████▍    | 463/857 [04:11<03:34,  1.84it/s, loss=0.145] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 73\u001b[0m\n\u001b[1;32m     67\u001b[0m mid_output, output \u001b[38;5;241m=\u001b[39m model(input_img) \u001b[38;5;66;03m#, break_flag用於調試\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#print(\"輸出最大值:\", output.max().item(), \"最小值:\", output.min().item())\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#print(\"中間輸出最大值:\", mid_output.max().item(), \"最小值:\", mid_output.min().item())\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# if break_flag: break\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# 反歸一化 output 和 target\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m output_denorm \u001b[38;5;241m=\u001b[39m \u001b[43mdenormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m mid_output_denorm \u001b[38;5;241m=\u001b[39m denormalize(mid_output, input_mean, input_std, device\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m target_denorm \u001b[38;5;241m=\u001b[39m denormalize(target_img, target_mean, target_std, device\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m, in \u001b[0;36mdenormalize\u001b[0;34m(tensor, mean, std, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdenormalize\u001b[39m(tensor, mean, std, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    反歸一化 Tensor 將 Normalize(mean, std) 轉回原始範圍\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 調整 shape 以匹配輸入\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(std)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor \u001b[38;5;241m*\u001b[39m std \u001b[38;5;241m+\u001b[39m mean\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load configuration from YAML file\n",
    "    config = load_config('config.yml')\n",
    "        \n",
    "    # 創建存放模型的資料夾\n",
    "    os.makedirs(config[\"checkpoint_dir\"], exist_ok=True)\n",
    "\n",
    "    # 創建模型\n",
    "    model = DPENet()\n",
    "    model.to(config[\"device\"])\n",
    "\n",
    "    # 創建損失函數\n",
    "    ssim_loss = SSIMLoss_v2().to(config[\"device\"])\n",
    "    edge_loss = EdgeLoss_v2().to(config[\"device\"])\n",
    "    l1_loss = L1Loss(loss_weight=1.0, reduction='mean').to(config[\"device\"])\n",
    "\n",
    "    # 創建優化器 & 學習率調整器\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], \n",
    "                            betas=(0.9 , 0.999), weight_decay=0)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 50, 80], gamma=0.2)\n",
    "\n",
    "    \"\"\"\n",
    "    scheduler = CosineAnnealingRestartCyclicLR(optimizer, periods=config[\"periods\"], \n",
    "                                            restart_weights=config[\"restart_weights\"], \n",
    "                                            eta_mins=[config[\"lr\"], config[\"eta_min\"]])\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # 1️⃣ 先計算 mean/std（現在可以直接指定 `mode` 和 `dataset_name`）\n",
    "    input_mean, input_std, target_mean, target_std = compute_mean_std(\n",
    "        mode='train', dataset_name=config[\"dataset_name\"], device=config[\"device\"])\n",
    "    \"\"\"\n",
    "    input_mean = [0.5110453963279724, 0.5104997158050537, 0.4877311885356903]\n",
    "    input_std = [0.23112213611602783, 0.23167330026626587, 0.23953330516815186]\n",
    "\n",
    "    target_mean = [0.43193507194519043, 0.43070125579833984, 0.4052175283432007]\n",
    "    target_std = [0.24484442174434662, 0.2445715367794037, 0.25179967284202576]\n",
    "    \n",
    "    # 2️⃣ 創建數據集，並直接應用計算好的 `mean/std`\n",
    "    #train_dataset = RainDataset(mode='train', dataset_name=config[\"dataset_name\"], transform=get_transform(input_mean, input_std, train=True))\n",
    "    train_dataset = RainDataset(mode='train', dataset_name=config[\"dataset_name\"], \n",
    "                            transform=get_transform(train=True))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config[\"batch_size\"], \n",
    "                                            shuffle=True, num_workers=4)\n",
    "\n",
    "    # 設定 AMP（混合精度）\n",
    "    scaler = GradScaler('cuda', enabled=config[\"use_amp\"])\n",
    "    # 訓練迴圈\n",
    "    print(f\"開始訓練 DPENet_CFIM，使用設備：{config['device']}\")\n",
    "    \n",
    "    break_flag = False\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        if break_flag: break\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{config['epochs']}]\")\n",
    "\n",
    "        for batch_idx, (input_img, target_img) in enumerate(pbar):\n",
    "            # print(\"輸入最大值:\", input_img.max().item(), \"最小值:\", input_img.min().item())\n",
    "            # print(\"目標最大值:\", target_img.max().item(), \"最小值:\", target_img.min().item())\n",
    "            input_img, target_img = input_img.to(config[\"device\"]), target_img.to(config[\"device\"])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向傳播（AMP 混合精度）\n",
    "            with autocast(device_type='cuda', enabled=config[\"use_amp\"]):\n",
    "                mid_output, output = model(input_img) #, break_flag用於調試\n",
    "                #print(\"輸出最大值:\", output.max().item(), \"最小值:\", output.min().item())\n",
    "                #print(\"中間輸出最大值:\", mid_output.max().item(), \"最小值:\", mid_output.min().item())\n",
    "                # if break_flag: break\n",
    "                \n",
    "                # 反歸一化 output 和 target\n",
    "                output_denorm = denormalize(output, input_mean, input_std, device=config[\"device\"]).clamp(0, 1)\n",
    "                mid_output_denorm = denormalize(mid_output, input_mean, input_std, device=config[\"device\"]).clamp(0, 1)\n",
    "                target_denorm = denormalize(target_img, target_mean, target_std, device=config[\"device\"]).clamp(0, 1)\n",
    "                # 確保數據範圍\n",
    "                #print(f\"📊 反歸一化後 output 最大值: {output_denorm.max().item()}, 最小值: {output_denorm.min().item()}\")\n",
    "                #print(f\"📊 反歸一化後 target 最大值: {target_denorm.max().item()}, 最小值: {target_denorm.min().item()}\")\n",
    "\n",
    "                ssim_val = ssim_loss(output, target_img) + ssim_loss(mid_output, target_img)\n",
    "                edge_val = edge_loss(output, target_img) + edge_loss(mid_output, target_img)\n",
    "                \n",
    "                if torch.isnan(ssim_val) or torch.isinf(ssim_val):\n",
    "                    print(\"⚠ SSIM Loss 出錯\", ssim_val, input_img.sum(), target_img.sum())\n",
    "\n",
    "                if torch.isnan(edge_val) or torch.isinf(edge_val):\n",
    "                    print(\"⚠ Edge Loss 出錯\", edge_val, input_img.sum(), target_img.sum())\n",
    "\n",
    "                loss = ssim_val + 0.05 * edge_val\n",
    "\n",
    "            # 反向傳播\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # 梯度裁剪，防止梯度爆炸或震盪\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config[\"grad_clip\"])\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()  # 更新學習率\n",
    "\n",
    "            # 記錄 Loss\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % config[\"log_interval\"] == 0:\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        #print(f\"🔹 Epoch [{epoch+1}/{config['epochs']}], Loss: {avg_loss:.6f}, LR: {scheduler.get_lr()[0]:.8f}\")\n",
    "        print(f\"🔹 Epoch [{epoch+1}/{config['epochs']}], Loss: {avg_loss:.6f}\")\n",
    "\n",
    "        # 保存模型（每 10 個 Epoch 保存一次）\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            save_path = os.path.join(config[\"checkpoint_dir\"], f\"DPENet_w_mid_epoch{epoch+1}.pth\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"模型已保存：{save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd73d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
