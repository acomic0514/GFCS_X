{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360e1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "from metrics.dataloader import RainDataset, get_transform, compute_mean_std\n",
    "\n",
    "# Import modules\n",
    "from models.archs.DPENet_v1 import DPENet\n",
    "from models.archs.DPENet_v3 import DPENet_v3\n",
    "from models.archs.losses import SSIMLoss_v2, EdgeLoss_v2, L1Loss\n",
    "from models.CosineAnnealingRestartCyclicLR import CosineAnnealingRestartCyclicLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7593ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    \n",
    "    # Ensure specific types\n",
    "    config[\"epochs\"] = int(config[\"epochs\"])\n",
    "    config[\"batch_size\"] = int(config[\"batch_size\"])\n",
    "    config[\"lr\"] = float(config[\"lr\"])\n",
    "    config[\"eta_min\"] = float(config[\"eta_min\"])\n",
    "    config[\"periods\"] = [int(period) for period in config[\"periods\"]]\n",
    "    config[\"restart_weights\"] = [float(weight) for weight in config[\"restart_weights\"]]\n",
    "    config[\"num_workers\"] = int(config[\"num_workers\"])\n",
    "    config[\"log_interval\"] = int(config[\"log_interval\"])\n",
    "    config[\"use_amp\"] = bool(config[\"use_amp\"])\n",
    "    config[\"grad_clip\"] = float(config[\"grad_clip\"])  # æ–°å¢æ¢¯åº¦è£å‰ªé–¾å€¼ï¼Œé è¨­ç‚º 1.0\n",
    "    \n",
    "    return config\n",
    "\n",
    "def denormalize(tensor, mean, std, device='cpu'):\n",
    "    \"\"\"\n",
    "    åæ­¸ä¸€åŒ– Tensor å°‡ Normalize(mean, std) è½‰å›åŸå§‹ç¯„åœ\n",
    "    \"\"\"\n",
    "    mean = torch.tensor(mean).view(1, -1, 1, 1).to(device)  # èª¿æ•´ shape ä»¥åŒ¹é…è¼¸å…¥\n",
    "    std = torch.tensor(std).view(1, -1, 1, 1).to(device)\n",
    "    return tensor * std + mean  # åæ­¸ä¸€åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f09b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é–‹å§‹è¨“ç·´ DPENet_CFIMï¼Œä½¿ç”¨è¨­å‚™ï¼šcuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/200]:   0%|          | 0/857 [00:00<?, ?it/s]/home/shuhao/GFCS_X/models/archs/modules.py:670: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epoch [1/200]:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 463/857 [04:11<03:34,  1.84it/s, loss=0.145] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 73\u001b[0m\n\u001b[1;32m     67\u001b[0m mid_output, output \u001b[38;5;241m=\u001b[39m model(input_img) \u001b[38;5;66;03m#, break_flagç”¨æ–¼èª¿è©¦\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#print(\"è¼¸å‡ºæœ€å¤§å€¼:\", output.max().item(), \"æœ€å°å€¼:\", output.min().item())\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#print(\"ä¸­é–“è¼¸å‡ºæœ€å¤§å€¼:\", mid_output.max().item(), \"æœ€å°å€¼:\", mid_output.min().item())\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# if break_flag: break\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# åæ­¸ä¸€åŒ– output å’Œ target\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m output_denorm \u001b[38;5;241m=\u001b[39m \u001b[43mdenormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m mid_output_denorm \u001b[38;5;241m=\u001b[39m denormalize(mid_output, input_mean, input_std, device\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m target_denorm \u001b[38;5;241m=\u001b[39m denormalize(target_img, target_mean, target_std, device\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m, in \u001b[0;36mdenormalize\u001b[0;34m(tensor, mean, std, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdenormalize\u001b[39m(tensor, mean, std, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    åæ­¸ä¸€åŒ– Tensor å°‡ Normalize(mean, std) è½‰å›åŸå§‹ç¯„åœ\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# èª¿æ•´ shape ä»¥åŒ¹é…è¼¸å…¥\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(std)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor \u001b[38;5;241m*\u001b[39m std \u001b[38;5;241m+\u001b[39m mean\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load configuration from YAML file\n",
    "    config = load_config('config.yml')\n",
    "        \n",
    "    # å‰µå»ºå­˜æ”¾æ¨¡å‹çš„è³‡æ–™å¤¾\n",
    "    os.makedirs(config[\"checkpoint_dir\"], exist_ok=True)\n",
    "\n",
    "    # å‰µå»ºæ¨¡å‹\n",
    "    model = DPENet()\n",
    "    model.to(config[\"device\"])\n",
    "\n",
    "    # å‰µå»ºæå¤±å‡½æ•¸\n",
    "    ssim_loss = SSIMLoss_v2().to(config[\"device\"])\n",
    "    edge_loss = EdgeLoss_v2().to(config[\"device\"])\n",
    "    l1_loss = L1Loss(loss_weight=1.0, reduction='mean').to(config[\"device\"])\n",
    "\n",
    "    # å‰µå»ºå„ªåŒ–å™¨ & å­¸ç¿’ç‡èª¿æ•´å™¨\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], \n",
    "                            betas=(0.9 , 0.999), weight_decay=0)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 50, 80], gamma=0.2)\n",
    "\n",
    "    \"\"\"\n",
    "    scheduler = CosineAnnealingRestartCyclicLR(optimizer, periods=config[\"periods\"], \n",
    "                                            restart_weights=config[\"restart_weights\"], \n",
    "                                            eta_mins=[config[\"lr\"], config[\"eta_min\"]])\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # 1ï¸âƒ£ å…ˆè¨ˆç®— mean/stdï¼ˆç¾åœ¨å¯ä»¥ç›´æ¥æŒ‡å®š `mode` å’Œ `dataset_name`ï¼‰\n",
    "    input_mean, input_std, target_mean, target_std = compute_mean_std(\n",
    "        mode='train', dataset_name=config[\"dataset_name\"], device=config[\"device\"])\n",
    "    \"\"\"\n",
    "    input_mean = [0.5110453963279724, 0.5104997158050537, 0.4877311885356903]\n",
    "    input_std = [0.23112213611602783, 0.23167330026626587, 0.23953330516815186]\n",
    "\n",
    "    target_mean = [0.43193507194519043, 0.43070125579833984, 0.4052175283432007]\n",
    "    target_std = [0.24484442174434662, 0.2445715367794037, 0.25179967284202576]\n",
    "    \n",
    "    # 2ï¸âƒ£ å‰µå»ºæ•¸æ“šé›†ï¼Œä¸¦ç›´æ¥æ‡‰ç”¨è¨ˆç®—å¥½çš„ `mean/std`\n",
    "    #train_dataset = RainDataset(mode='train', dataset_name=config[\"dataset_name\"], transform=get_transform(input_mean, input_std, train=True))\n",
    "    train_dataset = RainDataset(mode='train', dataset_name=config[\"dataset_name\"], \n",
    "                            transform=get_transform(train=True))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config[\"batch_size\"], \n",
    "                                            shuffle=True, num_workers=4)\n",
    "\n",
    "    # è¨­å®š AMPï¼ˆæ··åˆç²¾åº¦ï¼‰\n",
    "    scaler = GradScaler('cuda', enabled=config[\"use_amp\"])\n",
    "    # è¨“ç·´è¿´åœˆ\n",
    "    print(f\"é–‹å§‹è¨“ç·´ DPENet_CFIMï¼Œä½¿ç”¨è¨­å‚™ï¼š{config['device']}\")\n",
    "    \n",
    "    break_flag = False\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        if break_flag: break\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{config['epochs']}]\")\n",
    "\n",
    "        for batch_idx, (input_img, target_img) in enumerate(pbar):\n",
    "            # print(\"è¼¸å…¥æœ€å¤§å€¼:\", input_img.max().item(), \"æœ€å°å€¼:\", input_img.min().item())\n",
    "            # print(\"ç›®æ¨™æœ€å¤§å€¼:\", target_img.max().item(), \"æœ€å°å€¼:\", target_img.min().item())\n",
    "            input_img, target_img = input_img.to(config[\"device\"]), target_img.to(config[\"device\"])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # å‰å‘å‚³æ’­ï¼ˆAMP æ··åˆç²¾åº¦ï¼‰\n",
    "            with autocast(device_type='cuda', enabled=config[\"use_amp\"]):\n",
    "                mid_output, output = model(input_img) #, break_flagç”¨æ–¼èª¿è©¦\n",
    "                #print(\"è¼¸å‡ºæœ€å¤§å€¼:\", output.max().item(), \"æœ€å°å€¼:\", output.min().item())\n",
    "                #print(\"ä¸­é–“è¼¸å‡ºæœ€å¤§å€¼:\", mid_output.max().item(), \"æœ€å°å€¼:\", mid_output.min().item())\n",
    "                # if break_flag: break\n",
    "                \n",
    "                # åæ­¸ä¸€åŒ– output å’Œ target\n",
    "                output_denorm = denormalize(output, input_mean, input_std, device=config[\"device\"]).clamp(0, 1)\n",
    "                mid_output_denorm = denormalize(mid_output, input_mean, input_std, device=config[\"device\"]).clamp(0, 1)\n",
    "                target_denorm = denormalize(target_img, target_mean, target_std, device=config[\"device\"]).clamp(0, 1)\n",
    "                # ç¢ºä¿æ•¸æ“šç¯„åœ\n",
    "                #print(f\"ğŸ“Š åæ­¸ä¸€åŒ–å¾Œ output æœ€å¤§å€¼: {output_denorm.max().item()}, æœ€å°å€¼: {output_denorm.min().item()}\")\n",
    "                #print(f\"ğŸ“Š åæ­¸ä¸€åŒ–å¾Œ target æœ€å¤§å€¼: {target_denorm.max().item()}, æœ€å°å€¼: {target_denorm.min().item()}\")\n",
    "\n",
    "                ssim_val = ssim_loss(output, target_img) + ssim_loss(mid_output, target_img)\n",
    "                edge_val = edge_loss(output, target_img) + edge_loss(mid_output, target_img)\n",
    "                \n",
    "                if torch.isnan(ssim_val) or torch.isinf(ssim_val):\n",
    "                    print(\"âš  SSIM Loss å‡ºéŒ¯\", ssim_val, input_img.sum(), target_img.sum())\n",
    "\n",
    "                if torch.isnan(edge_val) or torch.isinf(edge_val):\n",
    "                    print(\"âš  Edge Loss å‡ºéŒ¯\", edge_val, input_img.sum(), target_img.sum())\n",
    "\n",
    "                loss = ssim_val + 0.05 * edge_val\n",
    "\n",
    "            # åå‘å‚³æ’­\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸æˆ–éœ‡ç›ª\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config[\"grad_clip\"])\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()  # æ›´æ–°å­¸ç¿’ç‡\n",
    "\n",
    "            # è¨˜éŒ„ Loss\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % config[\"log_interval\"] == 0:\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        #print(f\"ğŸ”¹ Epoch [{epoch+1}/{config['epochs']}], Loss: {avg_loss:.6f}, LR: {scheduler.get_lr()[0]:.8f}\")\n",
    "        print(f\"ğŸ”¹ Epoch [{epoch+1}/{config['epochs']}], Loss: {avg_loss:.6f}\")\n",
    "\n",
    "        # ä¿å­˜æ¨¡å‹ï¼ˆæ¯ 10 å€‹ Epoch ä¿å­˜ä¸€æ¬¡ï¼‰\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            save_path = os.path.join(config[\"checkpoint_dir\"], f\"DPENet_w_mid_epoch{epoch+1}.pth\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"æ¨¡å‹å·²ä¿å­˜ï¼š{save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd73d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
