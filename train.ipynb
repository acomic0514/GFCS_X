{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b8761-a5b5-49ab-9b93-7ebb58655e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import modules\n",
    "from GFCS_X_mod1 import GFCS_X, L1Loss\n",
    "from CosineAnnealingRestartCyclicLR import CosineAnnealingRestartCyclicLR\n",
    "# 這裡應該還有 DataLoader，但你之後會補上\n",
    "# from dataset import CustomDataset \n",
    "\n",
    "# 設定超參數\n",
    "CONFIG = {\n",
    "    \"epochs\": 100,  # 訓練輪數\n",
    "    \"batch_size\": 8,  # 每批次處理的圖片數\n",
    "    \"lr\": 3e-4,  # 初始學習率\n",
    "    \"eta_min\": 1e-6,  # 最小學習率\n",
    "    \"periods\": [92000, 208000],  # 餘弦衰減週期\n",
    "    \"restart_weights\": [1, 1],  # 週期重啟時的學習率比例\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"num_workers\": 4,  # DataLoader 進程數\n",
    "    \"checkpoint_dir\": \"checkpoints\",  # 存放模型\n",
    "    \"log_interval\": 10,  # 幾個 batch 記錄一次 Loss\n",
    "    \"use_amp\": True,  # 是否使用混合精度\n",
    "}\n",
    "\n",
    "# 創建存放模型的資料夾\n",
    "os.makedirs(CONFIG[\"checkpoint_dir\"], exist_ok=True)\n",
    "\n",
    "# 創建模型\n",
    "model = GFCS_X(inp_channels=3, out_channels=3, dim=48)\n",
    "model.to(CONFIG[\"device\"])\n",
    "model.half()  # ✅ 確保模型參數使用 float16\n",
    "\n",
    "# 創建損失函數\n",
    "criterion = L1Loss().to(CONFIG[\"device\"])\n",
    "\n",
    "# 創建優化器 & 學習率調整器\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG[\"lr\"], betas=(0.9, 0.999), weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingRestartCyclicLR(\n",
    "    optimizer, periods=CONFIG[\"periods\"], restart_weights=CONFIG[\"restart_weights\"], eta_mins=[CONFIG[\"lr\"], CONFIG[\"eta_min\"]]\n",
    ")\n",
    "\n",
    "# 設定 DataLoader（這部分等你有 Dataset 再補上）\n",
    "# train_dataset = CustomDataset(train_data_path)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=CONFIG[\"num_workers\"], pin_memory=True)\n",
    "\n",
    "# 設定 AMP（混合精度）\n",
    "scaler = GradScaler(enabled=CONFIG[\"use_amp\"])\n",
    "\n",
    "# 訓練迴圈\n",
    "def train():\n",
    "    print(f\"開始訓練 GFCS_X，使用設備：{CONFIG['device']}\")\n",
    "    for epoch in range(CONFIG[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{CONFIG['epochs']}]\", ncols=100)\n",
    "\n",
    "        for batch_idx, (input_img, target_img) in enumerate(pbar):\n",
    "            input_img, target_img = input_img.to(CONFIG[\"device\"]).half(), target_img.to(CONFIG[\"device\"]).half()  # ✅ 確保輸入是 float16\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向傳播（AMP 混合精度）\n",
    "            with torch.cuda.amp.autocast(enabled=CONFIG[\"use_amp\"]):  # ✅ 在 AMP 模式下前向傳播\n",
    "                output = model(input_img)\n",
    "                loss = criterion(output, target_img)\n",
    "\n",
    "            # 反向傳播\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()  # 更新學習率\n",
    "\n",
    "            # 記錄 Loss\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % CONFIG[\"log_interval\"] == 0:\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"🔹 Epoch [{epoch+1}/{CONFIG['epochs']}], Loss: {avg_loss:.6f}, LR: {scheduler.get_last_lr()[0]:.8f}\")\n",
    "\n",
    "        # 保存模型（每 10 個 Epoch 保存一次）\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            save_path = os.path.join(CONFIG[\"checkpoint_dir\"], f\"GFCS_X_epoch{epoch+1}.pth\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"模型已保存：{save_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83afa7b3-56e6-4e2f-bca0-863c1a34ccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train.ipynb to script\n",
      "[NbConvertApp] Writing 3183 bytes to train.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script train.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a8f9f-3253-47fb-9f1c-caff3cfe46f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (py310_env)",
   "language": "python",
   "name": "py310_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
